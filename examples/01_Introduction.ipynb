{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction to Genki Signals"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Signal Sources and Samplers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/egill/dev/genki/genki-signals/examples\r\n"
     ]
    }
   ],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# this isn't required with library pip installed\n",
    "os.chdir('../')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first building block of Genki Signals is the `SignalSource`\n",
    "\n",
    "SignalSource is a callable that returns the current value of that Signal. It can be a function or a class with a `__call__` method. One example is the `MouseSignalSource` that gives the current position of the pointer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([511.67578125, 406.46875   ])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from genki_signals.signal_sources import MouseSignalSource\n",
    "\n",
    "source = MouseSignalSource()\n",
    "source()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Obviously we want to gather multiple samples of this signal. For that we need a `Sampler`.\n",
    "\n",
    "A Sampler simply samples one or many SignalSources at a given _sample rate_:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from genki_signals.signal_sources import Sampler\n",
    "\n",
    "# sources is a dictionary mapping names to signal esources\n",
    "sampler = Sampler(sources = {\"mouse\": source}, sample_rate=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now the sampler samples the mouse position at a rate of 100 samples / second (hz) (This happens in a separate thread so the cell still returns and the main thread is unblocked.)\n",
    "\n",
    "Signal Sources and Samplers are the way to get raw data into Genki Signals, usually from some external source, like a web API or an external device. Sometimes these will be combined into a single class, e.g. a microphone that samples audio data at a specific sample rate which we have no control over, but more on that later."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Signal Functions and Systems"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We might want to do some processing on the samples from our sampler. \n",
    "\n",
    "This is where SignalFunctions come in. SignalFunctions are functions that take in one or more signals and return another signal.\n",
    "\n",
    "There is a collection of SignalFunctions available in `genki_signals.signal_functions` and they all have a similar structure, to create one you need to specify some _input names_ and also a _name_ for the output signal: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import genki_signals.signal_functions as sf\n",
    "\n",
    "# diff differentiates the \"mouse\" signals with regard to the \"timestamp\" and returns the signal \"mouse_vel\"\n",
    "# the \"mouse\" signal is the one we created earlier and \"timestamp\" is created automatically by the sampler\n",
    "\n",
    "diff = sf.Differentiate(input_a=\"mouse\", input_b=\"timestamp\", name=\"mouse_vel\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to introduce one more concept to connect all of this together: the SignalSystem.\n",
    "\n",
    "SignalSystem takes in a Sampler/SignalSource and a list of SignalFunctions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from genki_signals.signal_system import SignalSystem\n",
    "\n",
    "system = SignalSystem(sampler, [diff])\n",
    "\n",
    "system.start()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `signal_functions` module contains a library of functions to do signal arithmetic, digital signal processing, e.g. filtering, geometric calculations (useful for IMU sensors), create basic waveforms, run real time inference with machine learningh models, and more. We will dive into these in depth later."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the minimal setup we need. With a system, we can add signal functions to do all kinds of processing, and we can do data recording to start building a dataset. However, probably the most useful part of Genki Signals is the real-time visualization. For that we need a `Frontend`: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "registering data feed\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dd9b145c674a4bb7a9384300db337d04",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HBox(children=(Figure(axes=[Axis(label='timestamp', scale=LinearScale()), Axis(label='mouse', oâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updating widgets\n",
      "Updating widgets\n",
      "Updating widgets\n",
      "Updating widgets\n",
      "Updating widgets\n",
      "Updating widgets\n",
      "Updating widgets\n",
      "Updating widgets\n",
      "Updating widgets\n",
      "Updating widgets\n",
      "Updating widgets\n",
      "Updating widgets\n",
      "Updating widgets\n",
      "Updating widgets\n",
      "Updating widgets\n",
      "Updating widgets\n",
      "Updating widgets\n",
      "Updating widgets\n",
      "Updating widgets\n",
      "Updating widgets\n",
      "Updating widgets\n",
      "Updating widgets\n",
      "Updating widgets\n",
      "Updating widgets\n",
      "Updating widgets\n",
      "Updating widgets\n",
      "Updating widgets\n",
      "Updating widgets\n",
      "Updating widgets\n",
      "Updating widgets\n",
      "Updating widgets\n",
      "Updating widgets\n",
      "Updating widgets\n",
      "Updating widgets\n",
      "Updating widgets\n",
      "Updating widgets\n",
      "Updating widgets\n",
      "Updating widgets\n",
      "Updating widgets\n",
      "Updating widgets\n",
      "Updating widgets\n",
      "Updating widgets\n",
      "Updating widgets\n",
      "Updating widgets\n",
      "Updating widgets\n",
      "Updating widgets\n",
      "Updating widgets\n",
      "Updating widgets\n",
      "Updating widgets\n",
      "Updating widgets\n",
      "Updating widgets\n",
      "Updating widgets\n",
      "Updating widgets\n",
      "Updating widgets\n",
      "Updating widgets\n",
      "Updating widgets\n",
      "Updating widgets\n",
      "Updating widgets\n",
      "Updating widgets\n",
      "Updating widgets\n",
      "Updating widgets\n",
      "Updating widgets\n",
      "Updating widgets\n",
      "Updating widgets\n",
      "Updating widgets\n",
      "Updating widgets\n",
      "Updating widgets\n",
      "Updating widgets\n",
      "Updating widgets\n",
      "Updating widgets\n",
      "Updating widgets\n",
      "Updating widgets\n",
      "Updating widgets\n",
      "Updating widgets\n",
      "Updating widgets\n",
      "Updating widgets\n",
      "Updating widgets\n",
      "Updating widgets\n",
      "Updating widgets\n",
      "Updating widgets\n",
      "Updating widgets\n",
      "Updating widgets\n",
      "Updating widgets\n",
      "Updating widgets\n",
      "Updating widgets\n",
      "Updating widgets\n",
      "Updating widgets\n",
      "Updating widgets\n",
      "Updating widgets\n",
      "Updating widgets\n",
      "Updating widgets\n",
      "Updating widgets\n",
      "Updating widgets\n",
      "Updating widgets\n",
      "Updating widgets\n",
      "Updating widgets\n",
      "Updating widgets\n",
      "Updating widgets\n",
      "Updating widgets\n",
      "Updating widgets\n",
      "Updating widgets\n",
      "Updating widgets\n",
      "Updating widgets\n",
      "Updating widgets\n",
      "Updating widgets\n",
      "Updating widgets\n",
      "Updating widgets\n",
      "Updating widgets\n",
      "Updating widgets\n",
      "Updating widgets\n",
      "Updating widgets\n",
      "Updating widgets\n",
      "Updating widgets\n",
      "Updating widgets\n",
      "Updating widgets\n",
      "Updating widgets\n",
      "Updating widgets\n",
      "Updating widgets\n",
      "Updating widgets\n",
      "Updating widgets\n",
      "Updating widgets\n",
      "Updating widgets\n",
      "Updating widgets\n",
      "Updating widgets\n",
      "Updating widgets\n",
      "Updating widgets\n",
      "Updating widgets\n",
      "Updating widgets\n",
      "Updating widgets\n",
      "Updating widgets\n",
      "Updating widgets\n",
      "Updating widgets\n",
      "Updating widgets\n",
      "Updating widgets\n",
      "Updating widgets\n",
      "Updating widgets\n",
      "Updating widgets\n",
      "Updating widgets\n",
      "Updating widgets\n",
      "Updating widgets\n",
      "Updating widgets\n",
      "Updating widgets\n",
      "Updating widgets\n",
      "Updating widgets\n",
      "Updating widgets\n",
      "Updating widgets\n",
      "Updating widgets\n",
      "Updating widgets\n",
      "Updating widgets\n",
      "Updating widgets\n",
      "Updating widgets\n",
      "Updating widgets\n",
      "Updating widgets\n",
      "Updating widgets\n",
      "Updating widgets\n",
      "Updating widgets\n",
      "Updating widgets\n",
      "Updating widgets\n",
      "Updating widgets\n",
      "Updating widgets\n",
      "Updating widgets\n",
      "Updating widgets\n",
      "Updating widgets\n",
      "Updating widgets\n",
      "Updating widgets\n",
      "Updating widgets\n",
      "Updating widgets\n",
      "Updating widgets\n",
      "Updating widgets\n"
     ]
    }
   ],
   "source": [
    "from genki_signals.signal_frontends import WidgetFrontend, Line\n",
    "\n",
    "l_position = Line(\"timestamp\", \"mouse\")\n",
    "l_velocity = Line(\"timestamp\", \"mouse_vel\")\n",
    "\n",
    "dashboard = WidgetFrontend(system, widgets=[l_position, l_velocity])\n",
    "dashboard"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A `WidgetFrontend` is a front end specifically designed for jupyter notebooks. In the above cell we create two `Line` widgets and combine them into a `dashboard` object that is then rendered in a notebook. A Genki Signals frontend can also be a separate web server or any sort of GUI to visualize and interact with the system. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Recording data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our `dashboard` object displays the data in real time. The last basic feature we will introduce is recording. To start recording data, we can simply call `system.start_recording()` and give it a filename:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "system.start_recording('session_1')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The name `session_1` will be the name of a folder. We'll see its contents in a bit.\n",
    "\n",
    "We are now recording data, try moving the mouse around a bit and run the next cell to stop recording (and stop everything):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updating widgets\n",
      "Updating widgets\n"
     ]
    }
   ],
   "source": [
    "system.stop_recording()\n",
    "system.stop()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The system created the folder `session_1`, let's see what it contains:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "metadata.json   raw_data.pickle\r\n"
     ]
    }
   ],
   "source": [
    "!ls session_1/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`raw_data.pickle` contains the recorded data, whereas `metadata.json` contains various information about this recording session. Instead of reading these files directly we can load them in a `Session`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 1652)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from genki_signals.session import Session\n",
    "\n",
    "session = Session.from_filename('session_1')\n",
    "session.data['mouse'].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So we have a dataset of mouse positions! \n",
    "\n",
    "Note that we don't actually store the differentiated signal `mouse_vel`, we only store the raw data which is treated as a source of truth. The `SignalFunction`s are serialized and stored in `metadata.json`. All `SignalFunction`s are deterministic so they can be recomputed at will. This means that the signal functions (and their parameters, if any) can be used as hyperparameters in ML training. For example, if you want to use a low-pass filter on some signal, the exact cutoff frequency of the filter can be treated as a hyperparameter.\n",
    "\n",
    "The `metadata.json` can also contain arbitrary information about the particular session. This can also be useful in a machine learning setting if you wish to, for example, make sure the data is split into train and test based on _individuals_, so that no individual who appears in the test set has any data in the training set. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To recap, we have introduced a lot of concepts:\n",
    "\n",
    "* A `SignalSource` is some way to get an external signal\n",
    "* A `Sampler` samples values from a `SignalSource` at a given rate\n",
    "* A `SignalFunction` is some function to process signals\n",
    "* A `SignalSystem` ties all of the above together and records data\n",
    "* A `Session` is some data that was recorded in a single recording session\n",
    "* A `Frontend` is a way to visualize what is going on in a system and to interact with it\n",
    "\n",
    "We have only scratched the surface of these components. This should be enough to get started but in the following notebooks we will cover each of these in more depth."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "5d1ca8cbf69155084332556ae3352aa9e7bf4a96dd6bb5cc51f4289812d36157"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
