{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "089a03dc-48f4-404b-853a-92edc9cd020c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a824d440",
   "metadata": {},
   "source": [
    "The central concept of Genki Signals is the data buffer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0e9c0b53",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os \n",
    "os.chdir('/Users/egill/dev/genki/genki-signals')\n",
    "\n",
    "from genki_signals.buffers import DataBuffer\n",
    "\n",
    "buffer = DataBuffer(maxlen=400)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "845ad1f2",
   "metadata": {},
   "source": [
    "The `max_size` here is optional, but it makes the buffer circular, like a deque or queue, we can append to the end of it and if we append more than `max_size` elements, the oldest ones will automatically be deleted.\n",
    "\n",
    "Apart from that, a `DataBuffer` behaves similarly to a pandas `DataFrame`, except that series can be multi-dimensional. A `DataFrame` only maps names to `pandas` `Series`, which are similar to 1D `numpy` arrays. A `DataBuffer`, on the other hand, can map names to arrays of arbitrary dimension, whwere the first is assumed to represent time. For example, if we have a signal from an accelerometer, it is natural to think of it as a 3D signal - an array of shape `(n, 3)` for `n` samples. With a `DataBuffer`, we can do this, referring to the entire signal as `acc` and don't have to have 3 different signals, e.t. `acc_x`, `acc_y`, and `acc_z`. The convenience of this will become clear later when we start defining operations on signals. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7e53bc0",
   "metadata": {
    "tags": []
   },
   "source": [
    "A buffer without data is like a book without words, so let's generate some data! We'll make a simple sine wave generator to begin with:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "77dfdcc8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from genki_signals.data_sources import Sampler\n",
    "\n",
    "def make_sine_wave(freq, amplitude, phase):\n",
    "    def f(t):\n",
    "        return amplitude * np.sin(freq * 2 * np.pi * t + phase)\n",
    "    return f\n",
    "\n",
    "sine_wave = make_sine_wave(3, 5, 0)\n",
    "sine_sampler = Sampler(sources={'sine': sine_wave}, sample_rate=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6b53c07-2916-4eb8-a879-add9b00c576c",
   "metadata": {},
   "source": [
    "The `sine_wave` here is just a simple function of time, it can generate data at arbitrary frequency. To create a data generator, we need a `Sampler` - in this case we use the `rate` parameter to create one that samples at 100 samples per second. The sampler can combine multiple data generators but requires a name to make sense of the resulting data points. \n",
    "\n",
    "The unit of the `t` parameter that gets passed to the sine function is seconds, which means the sine wave has a frequency of 3 cycles per second - note that time here is not some abstract x-axis but actually real time. Once this data source gets going it will generate a sine wave with frequency 3 Hz, sampled at 100 Hz. We can now generate data in a separate thread, leaving the main thread unblocked:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6edbbcae",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import time\n",
    "from threading import Thread\n",
    "\n",
    "from genki_signals.data_sources import SineWave\n",
    "\n",
    "buffer = DataBuffer(maxlen=400)\n",
    "sine_wave = SineWave(frequency=3, amplitude=5, phase=0)\n",
    "source = Sampler(sources={'sine': sine_wave}, sample_rate=100)\n",
    "\n",
    "def run_source():\n",
    "    source.start()\n",
    "    while True:\n",
    "        buffer.extend(source.read())\n",
    "        time.sleep(1 / 25)\n",
    "        if not source.is_active:\n",
    "            return\n",
    "        \n",
    "t = Thread(target=run_source)\n",
    "t.start()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c013ee5",
   "metadata": {},
   "source": [
    "Here we import the `SineWave` class from genki signals. This works exactly the same as using the function we defined previously, but the parameters (frequency, amplitude, and phase) are stored as instance variables, which means we can change them post-hoc and the generated data will update in real time.\n",
    "\n",
    "As soon as the `start` method of the data source is called, it starts generating data on a sampling rate of 100 Hz. This happens in a separate thread, so we are actually spawning two threads here: one to generate the data and another one to regularly poll the source for new data and put it in a buffer.\n",
    "\n",
    "Calling `source.read()` returns all data that the source has generated since the last call to `read`. In this case we are calling `read` 25 times a second, but the data source is generating data at 100 Hz, so we should expect `read` to return 4 data points on average. \n",
    "\n",
    "Effectively, there are three frequencies at play here:\n",
    "* The sine wave frequency (3 Hz)\n",
    "* The sample rate (100 Hz)\n",
    "* The _update frequency_ (25 Hz)\n",
    "\n",
    "The distinction between sampling rate and update frequency is very useful. The sample rate is often determined by the domain in question (e.g. a microphone samples at 44100 Hz) whereas the update frequency depends on what you are doing with the data. If we are recording data and flushing the data to disk occasionally, a very low update frequency makes sense. If we are plotting data on a real time dashboard, we  want a higher update frequency to make the animation smooth.\n",
    "\n",
    "Speaking of plots, a key feature of the data buffer is visualisation of the data as it is generated:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9ffa09c1-ebd3-4889-8756-d54162747ce4",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['timestamp', 'sine'])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "buffer.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3c8a341d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7719153035d149ddb056d137e26894b1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Figure(axes=[Axis(label='t', scale=LinearScale()), Axis(label='sine', orientation='vertical', scale=LinearScal…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "buffer.plot(key='sine')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ef9e80e-71f4-42e2-9477-b543b7bc0bb3",
   "metadata": {},
   "source": [
    "Because we are using the class `SineWave`, we can actually edit the wave parameters with everything running:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c504d17d-b643-4c78-8ed6-616d7d23b374",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "09e3632f099846208d10ac8abfc74b9f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(FloatSlider(value=5.0, description='amplitude', max=5.0, min=1.0, step=0.5), IntSlider(v…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from ipywidgets import interact, IntSlider, FloatSlider\n",
    "\n",
    "@interact(amplitude=FloatSlider(min=1, max=5, step=0.5, value=5), frequency=IntSlider(min=1, max=7, value=3))\n",
    "def set_wave_params(amplitude, frequency):\n",
    "    sine_wave.amplitude = amplitude\n",
    "    sine_wave.frequency = frequency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4b976e8d-1cda-4b47-a2a2-6126bdfa1367",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "source.stop()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09626dcc-1e07-471d-a158-949ba3f7c228",
   "metadata": {},
   "source": [
    "We can also use user input as a data source, for example through the mouse position, keys on a keyboard, microphone, or a Genki Wave smart ring:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7ddafe85",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from genki_signals.data_sources import MicDataSource, WaveDataSource, MouseDataSource, KeyboardDataSource\n",
    "\n",
    "mouse_source = Sampler({'mouse_position': MouseDataSource()}, sample_rate=100)\n",
    "keyboard_source = Sampler({'keyboard': KeyboardDataSource(keys=[\"enter\", \"shift\"])}, sample_rate=100)\n",
    "\n",
    "wave_source = WaveDataSource(ble_address='5C72E785-DAF5-1E32-599D-EBF56B8ECD5B')\n",
    "mic_source = MicDataSource()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "802bb247",
   "metadata": {},
   "source": [
    "The `MouseDataSource` reads the position of the mouse, the `KeyboardDataSource` detects whether the user is pressing the specified keys, `WaveDataSource` streams sensor data from a Wave ring, and the `MicDataSource` records audio from the microphone.\n",
    "\n",
    "There is a difference between `MouseDataSource` and `KeyboardDataSource` on the one hand and `WaveDataSource` and `MicDataSource` on the other. The former two need to be wrapped in a `Sampler` whereas the latter do not. The reason for this is that the mouse position and keyboard pressing information (like the sine wave) can be accessed/computed at any time whereas the Wave ring and the microphone sample data on their own frequencies which we have no control over (short of resampling the data). In a way, they act as a data source and a sampler combined. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ffa05136-4f3b-4286-b6be-fd29b62c98bd",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connecting to wave at address 5C72E785-DAF5-1E32-599D-EBF56B8ECD5B\n",
      "Connected to Wave\n"
     ]
    }
   ],
   "source": [
    "buffer = DataBuffer(maxlen=400)\n",
    "source = wave_source\n",
    "\n",
    "def run_source():\n",
    "    source.start()\n",
    "    while True:\n",
    "        buffer.extend(source.read())\n",
    "        time.sleep(1 / 25)\n",
    "        if not source.is_active:\n",
    "            return\n",
    "        \n",
    "t = Thread(target=run_source)\n",
    "t.start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "82ef55e7-7fef-491f-b670-edd3f8052cec",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['gyro', 'acc', 'mag', 'raw_pose', 'current_pose', 'euler', 'linacc', 'peak', 'peak_norm_velocity', 'timestamp_us', 'grav', 'acc_glob', 'linacc_glob'])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "buffer.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d3ccab7-ccad-42a0-9d89-f52662af3270",
   "metadata": {},
   "source": [
    "Some of the signals from the Wave ring are defined as multi-dimensional, for example we can plot the 3D gyroscope signal as a \"single thing\":"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4ef49c55-39ba-4317-a56d-329b1c8fb05a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f45b709b288641c7a1ac3b7af0f798a3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Figure(axes=[Axis(label='t', scale=LinearScale()), Axis(label='gyro', orientation='vertical', scale=LinearScal…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "buffer.plot(key='gyro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "faa761b2-d3dd-4464-a921-2e694b1fdf7a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Got a cancel message, exiting.\n"
     ]
    }
   ],
   "source": [
    "source.stop()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d161868e-3a89-46a9-b803-ac257137c1b9",
   "metadata": {},
   "source": [
    "## Derived signals"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebaecf94-f514-4968-bbf9-440b81c5327f",
   "metadata": {},
   "source": [
    "The real power of Genki Signals comes from using derived signals:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "37584413",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import genki_signals.signals as s\n",
    "\n",
    "derived_signals = [\n",
    "    s.Sum('sine_0', 'sine_1', name='composite_sine'),\n",
    "    s.Sum('composite_sine', 'noise', name='wave_with_noise'),\n",
    "    s.FourierTransform('wave_with_noise', name='wave_spectrum', window_size=256, window_overlap=128),\n",
    "    s.SampleRate('timestamp', name='sample_rate'),\n",
    "    s.MovingAverage('sample_rate', length=10, name='smooth_sample_rate'),\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee7500d8",
   "metadata": {},
   "source": [
    "What are `derived_signals`? It specifies a configuration of derived signals in the context of some data sources. Adding `sine_0` and `sine_1` is meaningless without knowing what `sine_0` and `sine_1` are.\n",
    "\n",
    "What do we want from an object like `derived_signals`?\n",
    "\n",
    "* It represents a DAG of time-series operations, each operation can take source signals or results of other operations as input. Names are important!\n",
    "* These should work both offline and online (real time). They are _causal_ in other words.\n",
    "* They should be deterministic - reproducible from the specification and input data only and can only depend on local state.\n",
    "* Determinism means they are serializable to e.g. JSON - this can be passed from frontend to backend in a web app \n",
    "* We can create a torch module (and sklearn pipeline) from a given list of derived signals and input/output names - which is then serializable as ONNX or tf-lite\n",
    "* This is tensor backend-agnostic. Each signal is capable of working with numpy arrays, torch tensors, etc.\n",
    "* Each signal in the list is a function that can operate independently given some data.\n",
    "\n",
    "We are still not computing any of the derived signals. If we want to use these signals, we need to manage all the names and call the signals with the right inputs at each step. This is exactly what a `System` does:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b1f86318",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from genki_signals.system import System\n",
    "from genki_signals.data_sources import RandomNoise\n",
    "\n",
    "sine_1 = SineWave(frequency=3, amplitude=5,phase=0)\n",
    "sine_2 = SineWave(frequency=7, amplitude=2, phase=0)\n",
    "noise_source = RandomNoise()\n",
    "\n",
    "data_source = Sampler({\n",
    "    'sine_0': sine_1,\n",
    "    'sine_1': sine_2,\n",
    "    'noise': noise_source\n",
    "}, sample_rate=100)\n",
    "\n",
    "buffer = DataBuffer(maxlen=400)\n",
    "\n",
    "system = System(\n",
    "    data_source=data_source,\n",
    "    derived_signals=derived_signals\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "cd3b98c2-1c7c-4dbf-879c-785562218b22",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import time\n",
    "from threading import Thread\n",
    "\n",
    "def run_system():\n",
    "    system.start()\n",
    "    while True:\n",
    "        buffer.extend(system.read())\n",
    "        time.sleep(1 / 25)\n",
    "        if not system.is_active: \n",
    "            return\n",
    "        \n",
    "t = Thread(target=run_system)\n",
    "t.start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9aafd9dc-74ab-4699-af4c-ee2cd02a134d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['timestamp', 'sine_0', 'sine_1', 'noise', 'composite_sine', 'wave_with_noise', 'wave_spectrum', 'sample_rate', 'smooth_sample_rate'])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "buffer.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d8374d8a-fa41-4a3b-aa2a-083b7317ce53",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2f37334e810147148678745de80280a5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Figure(axes=[Axis(label='t', scale=LinearScale()), Axis(label='wave_with_noise', orientation='vertical', scale…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "buffer.plot('wave_with_noise')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1f0f1c7d-9cd3-46ce-9174-a5940e1e0997",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "de0eb6b799754e6f9ca100b769c88b13",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(FloatSlider(value=1.0, description='noise', max=3.0, min=0.1), Output()), _dom_classes=(…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from ipywidgets import interact, FloatSlider\n",
    "\n",
    "@interact(noise=FloatSlider(min=0.1, max=3.0, step=0.1, value=1))\n",
    "def set_noise(noise):\n",
    "    noise_source.amplitude = noise"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fab93c40",
   "metadata": {},
   "source": [
    "Setting `plot_type` changes the type of plot created. Genki signals includes a few widgets for data visualisation. Here are a few examles:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "cef8128c-595c-490a-90ae-2e53500f0744",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "03e32ca5c6ce4fa48c00f62e794d378f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Figure(axes=[Axis(label='Hz', scale=LinearScale()), Axis(label='db', orientation='vertical', scale=LinearScale…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "buffer.plot(key='wave_spectrum', plot_type='spectrogram', sample_rate=100, window_size=256)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37e0797d-758c-4765-b683-8ce99ee3f3f2",
   "metadata": {},
   "source": [
    "We see spikes at frequencies 3 and 7 Hz, as expected. Note we can still adjust the noise and the spikes will become more/less clear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "5eff1812-a5fe-41db-8831-2b15b1b9f0ec",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "system.stop()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba912db7-d92f-4c0b-90d6-936bdc5428b7",
   "metadata": {},
   "source": [
    "We can add derived signals to a running system:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f2b85d45-abd7-443d-9700-f91d6e971afc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "mic_source = MicDataSource()\n",
    "\n",
    "buffer = DataBuffer(maxlen=400)\n",
    "\n",
    "\n",
    "system = System(\n",
    "    data_source=mic_source,\n",
    "    derived_signals=[]\n",
    ")\n",
    "\n",
    "def run_system():\n",
    "    system.start()\n",
    "    while True:\n",
    "        time.sleep(1 / 25)\n",
    "        buffer.extend(system.read())\n",
    "        if not system.is_active:\n",
    "            return\n",
    "        \n",
    "t = Thread(target=run_system)\n",
    "t.start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ba503818-4fdc-49a8-9f38-baffb46d7bbc",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['audio'])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "buffer.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d56829a5-ef41-476f-bcd6-d1d727f7eb78",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "system.add_derived_signal(s.FourierTransform('audio', 'audio_spectrum', window_size=1024, window_overlap=0, upsample=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "07fcec80-406e-4a61-b497-7e699c1afeb0",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['audio', 'audio_spectrum'])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "buffer.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "5ea293a4-633e-4673-87ca-5db0625ebbc4",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f5df530d6a8c4b978af7f878e5815abc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Figure(axes=[Axis(label='Hz', scale=LinearScale()), Axis(label='db', orientation='vertical', scale=LinearScale…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "buffer.plot(key='audio_spectrum', plot_type='spectrogram', sample_rate=mic_source.sample_rate, window_size=1024)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "cb636db1-b422-41a3-b121-8816c14010cf",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "system.stop()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d3e6df6-72b5-4750-a770-73564ee0d811",
   "metadata": {},
   "source": [
    "Note that since we pass `upsample=False` to the signal, the spectral signals is generated at a much lower frequency than the original (audio) one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "813f83f4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "mouse_system = System(mouse_source)\n",
    "buffer = DataBuffer(maxlen=400)\n",
    "\n",
    "def run_system():\n",
    "    mouse_system.start()\n",
    "    while True:\n",
    "        buffer.extend(mouse_system.read())\n",
    "        time.sleep(1 / 50)\n",
    "        if not mouse_system.is_active:\n",
    "            return\n",
    "        \n",
    "t = Thread(target=run_system)\n",
    "t.start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "fadff56c-e064-40e3-ae4e-fde2af56d82e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c8460d99d65f4befa244998f84cbb59e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Figure(axes=[Axis(label='x', scale=LinearScale()), Axis(label='y', orientation='vertical', scale=LinearScale()…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "buffer.plot(key='mouse_position', plot_type=\"trace2D\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "48b421b7-dfda-4891-ab5e-dc370b56843c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "mouse_system.stop()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8179c0e1",
   "metadata": {
    "tags": []
   },
   "source": [
    "# A note on clocks\n",
    "\n",
    "So far, some of the data sources we have seen have had to be wrappped in a `Sampler` to be used with the rest of Genki Signals, whereas some have not. We know the reason for this - external devices like a Wave ring have their own clock and sampling rate that we have no direct control over, packages just arrive via bluetooth when they do and synchronising clocks in a distributed system is virtually impossible.\n",
    "\n",
    "What if we want to combine multiple sources? What if we want to use data from, say, a Wave ring and the mouse, or two separate Wave rings? A `Sampler` object can easily sample from multiple data generators at a time - the way a `Sampler` works is that it simply runs a busy thread that wakes up at the specified frequency and reads data from all its sources, since these are all a simple function of time, this works out pretty well.\n",
    "\n",
    "But what if we want to mix and match sources that operate their own clock? The only sensible way to do this is to make one source the \"leader\" that works as the sampler in the example above, and make the others \"followers\" that work like the data generators. To make e.g. Wave a leader source with some followers, we would simply query all the followers for the current data point any time we receive a package from Wave. To make Wave act like a follower, we would need to run the receiver in a separate thread, and always keep the latest data point to answer queries from the leader. If the leader is operating at a lower sampling rate than Wave, some data points are simply ignored (implicit downsampling), whereas if the leader has a higher sampling rate, identical data points will be returned more than once (implicit upsampling). "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e1d23e4-916c-4715-973a-546addff060c",
   "metadata": {},
   "source": [
    "# Model inference\n",
    "\n",
    "Perhaps the most useful class of signals implemented by the system is model inference signals, the simplest one of which is `Inference`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "af4c90de-3d94-42b3-bd1e-8561a3ceb38e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from genki_signals.models.letter_detection_model import SimpleGruModel\n",
    "\n",
    "example_rnn_model = SimpleGruModel.load_from_checkpoint(\"genki_signals/models/stc_detector_final-epoch=15-val_loss=0.53.ckpt\")\n",
    "\n",
    "derived = [\n",
    "    s.Differentiate(\"mouse_position\", sig_b=\"timestamp\", name=\"mouse_velocity\"),\n",
    "    s.Inference(example_rnn_model, input_signal=\"mouse_velocity\", stateful=True, name=\"rnn_model_inference\")\n",
    "]\n",
    "\n",
    "mouse_source = Sampler({'mouse_position': MouseDataSource()}, sample_rate=100)\n",
    "system = System(mouse_source, derived_signals=derived)\n",
    "buffer = DataBuffer(maxlen=400)\n",
    "\n",
    "def run_system():\n",
    "    system.start()\n",
    "    while True:\n",
    "        buffer.extend(system.read())\n",
    "        time.sleep(1 / 50)\n",
    "        if not system.is_active:\n",
    "            return\n",
    "        \n",
    "t = Thread(target=run_system)\n",
    "t.start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "bca8dcfe-3e16-4e7c-b00e-1dc72b25885b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "32d2d17c1e6d4394a438040be266ccac",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Figure(axes=[Axis(scale=OrdinalScale()), Axis(label='Probability', orientation='vertical', scale=LinearScale()…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "buffer.plot('rnn_model_inference', plot_type='histogram', class_names=['background', 'square', 'triangle', 'circle'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "65077617-d665-4542-abf4-183f456b731f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "system.stop(); t.join()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "295e163e-d8f5-4f3f-b638-8cbc678cf0ab",
   "metadata": {
    "tags": []
   },
   "source": [
    "Here we have a model that is a _recurrent neural network_. Those are particularly simple to run in real time systems since they make a prediction at each time step. At each step they output a prediction vector and a state vector, and require an input vector and the previious state vector as input. The `Inference` signal handles this for us. An even simpler model would be one that takes in an input and outputs a prediction at each step independently, in that case `Inference` would also work, but with `stateful=False`.\n",
    "\n",
    "When you want to detect if/when the user drew a certain shape, outputting predictions at 100Hz is probably not exactly what you want. More likely is that you want to trigger some kind of event whenever it happened. You probably wouldn't want the event to be triggered repeatedly for what is actually the same movement"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87fea180-dc0f-466b-b8b9-a2d0eb2d5df4",
   "metadata": {
    "tags": []
   },
   "source": [
    "Some models would operate independently (i.e. without state) but on a windowed view of data at a time. A classic example of this are _Convolutional Neural Networks_:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "3ab36153-b54d-41ba-950f-6ea8817508c3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "derived = [\n",
    "    s.Concatenate(['linacc', 'gyro'], name='model_input'),\n",
    "    s.WindowedInference('genki_signals/models/model/model.onnx', 'model_input', \n",
    "                        name='swipe_inference', window_size=128, window_overlap=32, output_shape=(3,))\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "4eb60daf-0abf-41d4-919f-e9804ea8eb3e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception in thread Thread-15:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/egill/opt/miniconda3/envs/genki/lib/python3.9/asyncio/selector_events.py\", line 256, in _add_reader\n",
      "    key = self._selector.get_key(fd)\n",
      "  File \"/Users/egill/opt/miniconda3/envs/genki/lib/python3.9/selectors.py\", line 193, in get_key\n",
      "    raise KeyError(\"{!r} is not registered\".format(fileobj)) from None\n",
      "KeyError: '94 is not registered'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/egill/opt/miniconda3/envs/genki/lib/python3.9/threading.py\", line 973, in _bootstrap_inner\n",
      "Exception in thread Thread-14:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/egill/opt/miniconda3/envs/genki/lib/python3.9/threading.py\", line 973, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"/Users/egill/opt/miniconda3/envs/genki/lib/python3.9/threading.py\", line 910, in run\n",
      "    self.run()\n",
      "  File \"/Users/egill/opt/miniconda3/envs/genki/lib/python3.9/site-packages/genki_wave/threading_runner.py\", line 113, in run\n",
      "    loop = get_or_create_event_loop()\n",
      "  File \"/Users/egill/opt/miniconda3/envs/genki/lib/python3.9/site-packages/genki_wave/utils.py\", line 48, in get_or_create_event_loop\n",
      "    asyncio.set_event_loop(asyncio.new_event_loop())\n",
      "  File \"/Users/egill/opt/miniconda3/envs/genki/lib/python3.9/asyncio/events.py\", line 761, in new_event_loop\n",
      "    return get_event_loop_policy().new_event_loop()\n",
      "  File \"/Users/egill/opt/miniconda3/envs/genki/lib/python3.9/asyncio/events.py\", line 659, in new_event_loop\n",
      "    return self._loop_factory()\n",
      "  File \"/Users/egill/opt/miniconda3/envs/genki/lib/python3.9/asyncio/unix_events.py\", line 54, in __init__\n",
      "        self._target(*self._args, **self._kwargs)\n",
      "  File \"/var/folders/rn/w235gcs92m5bfdgr3qdmmnbm0000gn/T/ipykernel_71095/2605723155.py\", line 10, in run_system\n",
      "super().__init__(selector)\n",
      "  File \"/Users/egill/opt/miniconda3/envs/genki/lib/python3.9/asyncio/selector_events.py\", line 56, in __init__\n",
      "  File \"/Users/egill/dev/genki/genki-signals/genki_signals/system.py\", line 55, in read\n",
      "    self._make_self_pipe()\n",
      "  File \"/Users/egill/opt/miniconda3/envs/genki/lib/python3.9/asyncio/selector_events.py\", line 107, in _make_self_pipe\n",
      "    self._compute_derived(data)\n",
      "  File \"/Users/egill/dev/genki/genki-signals/genki_signals/system.py\", line 38, in _compute_derived\n",
      "    inputs = tuple(data[name] for name in signal.input_names)\n",
      "  File \"/Users/egill/dev/genki/genki-signals/genki_signals/system.py\", line 38, in <genexpr>\n",
      "    inputs = tuple(data[name] for name in signal.input_names)\n",
      "  File \"/Users/egill/dev/genki/genki-signals/genki_signals/buffers.py\", line 120, in __getitem__\n",
      "    raise KeyError(f\"Key {k} not found in {self.keys()}\")\n",
      "KeyError: \"Key m not found in dict_keys(['gyro', 'acc', 'mag', 'raw_pose', 'current_pose', 'euler', 'linacc', 'peak', 'peak_norm_velocity', 'timestamp_us', 'grav', 'acc_glob', 'linacc_glob', 'model_input'])\"\n",
      "    self._add_reader(self._ssock.fileno(), self._read_from_self)\n",
      "  File \"/Users/egill/opt/miniconda3/envs/genki/lib/python3.9/asyncio/selector_events.py\", line 258, in _add_reader\n",
      "    self._selector.register(fd, selectors.EVENT_READ,\n",
      "  File \"/Users/egill/opt/miniconda3/envs/genki/lib/python3.9/selectors.py\", line 523, in register\n",
      "    self._selector.control([kev], 0, 0)\n",
      "TypeError: changelist must be an iterable of select.kevent objects\n",
      "Exception ignored in: <function BaseEventLoop.__del__ at 0x103030c10>\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/egill/opt/miniconda3/envs/genki/lib/python3.9/asyncio/base_events.py\", line 688, in __del__\n",
      "    self.close()\n",
      "  File \"/Users/egill/opt/miniconda3/envs/genki/lib/python3.9/asyncio/unix_events.py\", line 60, in close\n",
      "    for sig in list(self._signal_handlers):\n",
      "AttributeError: '_UnixSelectorEventLoop' object has no attribute '_signal_handlers'\n",
      "/Users/egill/opt/miniconda3/envs/genki/lib/python3.9/threading.py:975: RuntimeWarning: coroutine 'bluetooth_task' was never awaited\n",
      "  self._invoke_excepthook(self)\n",
      "RuntimeWarning: Enable tracemalloc to get the object allocation traceback\n"
     ]
    }
   ],
   "source": [
    "from genki_signals.system import System\n",
    "\n",
    "#wave_source = WaveDataSource(ble_address='5C72E785-DAF5-1E32-599D-EBF56B8ECD5B')\n",
    "system = System(wave_source, derived_signals=derived)\n",
    "buffer = DataBuffer(maxlen=400)\n",
    "\n",
    "def run_system():\n",
    "    system.start()\n",
    "    while True:\n",
    "        buffer.extend(system.read())\n",
    "        time.sleep(1 / 50)\n",
    "        if not system.is_active:\n",
    "            return\n",
    "        \n",
    "t = Thread(target=run_system)\n",
    "t.start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c2aa8179-8481-49c6-ab89-f48654c252a3",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception in thread Thread-10:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/egill/opt/miniconda3/envs/genki/lib/python3.9/asyncio/selector_events.py\", line 256, in _add_reader\n",
      "    key = self._selector.get_key(fd)\n",
      "  File \"/Users/egill/opt/miniconda3/envs/genki/lib/python3.9/selectors.py\", line 193, in get_key\n",
      "    raise KeyError(\"{!r} is not registered\".format(fileobj)) from None\n",
      "KeyError: '77 is not registered'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/egill/opt/miniconda3/envs/genki/lib/python3.9/threading.py\", line 973, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"/Users/egill/opt/miniconda3/envs/genki/lib/python3.9/site-packages/genki_wave/threading_runner.py\", line 113, in run\n",
      "    loop = get_or_create_event_loop()\n",
      "  File \"/Users/egill/opt/miniconda3/envs/genki/lib/python3.9/site-packages/genki_wave/utils.py\", line 48, in get_or_create_event_loop\n",
      "    asyncio.set_event_loop(asyncio.new_event_loop())\n",
      "  File \"/Users/egill/opt/miniconda3/envs/genki/lib/python3.9/asyncio/events.py\", line 761, in new_event_loop\n",
      "    return get_event_loop_policy().new_event_loop()\n",
      "  File \"/Users/egill/opt/miniconda3/envs/genki/lib/python3.9/asyncio/events.py\", line 659, in new_event_loop\n",
      "    return self._loop_factory()\n",
      "  File \"/Users/egill/opt/miniconda3/envs/genki/lib/python3.9/asyncio/unix_events.py\", line 54, in __init__\n",
      "    super().__init__(selector)\n",
      "  File \"/Users/egill/opt/miniconda3/envs/genki/lib/python3.9/asyncio/selector_events.py\", line 56, in __init__\n",
      "    self._make_self_pipe()\n",
      "  File \"/Users/egill/opt/miniconda3/envs/genki/lib/python3.9/asyncio/selector_events.py\", line 107, in _make_self_pipe\n",
      "    self._add_reader(self._ssock.fileno(), self._read_from_self)\n",
      "  File \"/Users/egill/opt/miniconda3/envs/genki/lib/python3.9/asyncio/selector_events.py\", line 258, in _add_reader\n",
      "    self._selector.register(fd, selectors.EVENT_READ,\n",
      "  File \"/Users/egill/opt/miniconda3/envs/genki/lib/python3.9/selectors.py\", line 523, in register\n",
      "    self._selector.control([kev], 0, 0)\n",
      "TypeError: changelist must be an iterable of select.kevent objects\n",
      "Exception ignored in: <function BaseEventLoop.__del__ at 0x1055b8c10>\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/egill/opt/miniconda3/envs/genki/lib/python3.9/asyncio/base_events.py\", line 688, in __del__\n",
      "    self.close()\n",
      "  File \"/Users/egill/opt/miniconda3/envs/genki/lib/python3.9/asyncio/unix_events.py\", line 60, in close\n",
      "    for sig in list(self._signal_handlers):\n",
      "AttributeError: '_UnixSelectorEventLoop' object has no attribute '_signal_handlers'\n"
     ]
    }
   ],
   "source": [
    "wave_source.start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a6b5d952-5e61-4620-93e2-5837264502db",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from onnxruntime import InferenceSession\n",
    "\n",
    "session = InferenceSession('genki_signals/models/model/model.onnx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "59c45a7c-8893-440b-9d32-64f2e3d3a070",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "output, output_extra = session.run(['output', 'output_extra'], {\"input\": np.ones((1, 128, 6)).astype(np.float32)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "bba04e46-7fd4-4389-8aba-b2822b1a4422",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1, 3, 16), (1, 6, 128))"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output.shape, output_extra.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "99b3628b-9850-4ecf-8060-f2c3d4af1136",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 's' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[38], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43ms\u001b[49m\u001b[38;5;241m.\u001b[39mWindowedInference\n",
      "\u001b[0;31mNameError\u001b[0m: name 's' is not defined"
     ]
    }
   ],
   "source": [
    "s.WindowedInference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9a1759f4-185c-4a11-b155-68b618dc1a70",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Swipe demo? Object detection post-processing?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2dc8899-3de3-4d0a-b299-c436cd026a2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sklearn model demo?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da50b5aa",
   "metadata": {},
   "source": [
    "Other things to add to demo:\n",
    "\n",
    "* Demonstrate signal spec serialisation to e.g. ONNX\n",
    "* Synthesise some complex data\n",
    "* More signal processing magic - e.g. modulate a signal with noise and delay and demodulate, custom filter design with interactive parameter sliders\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "fe317d18",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[0;31mSignature:\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_names\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_feed\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_options\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
       "\u001b[0;31mDocstring:\u001b[0m\n",
       "Compute the predictions.\n",
       "\n",
       ":param output_names: name of the outputs\n",
       ":param input_feed: dictionary ``{ input_name: input_value }``\n",
       ":param run_options: See :class:`onnxruntime.RunOptions`.\n",
       "\n",
       "::\n",
       "\n",
       "    sess.run([output_name], {input_name: x})\n",
       "\u001b[0;31mFile:\u001b[0m      ~/opt/miniconda3/envs/genki/lib/python3.9/site-packages/onnxruntime/capi/onnxruntime_inference_collection.py\n",
       "\u001b[0;31mType:\u001b[0m      method"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "session.run?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f933443b-ce53-46c6-a514-c18d76a44b99",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[0;31mInit signature:\u001b[0m\n",
       "\u001b[0mInferenceSession\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mpath_or_bytes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0msess_options\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mproviders\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mprovider_options\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
       "\u001b[0;31mDocstring:\u001b[0m      This is the main class used to run a model.\n",
       "\u001b[0;31mInit docstring:\u001b[0m\n",
       ":param path_or_bytes: filename or serialized ONNX or ORT format model in a byte string\n",
       ":param sess_options: session options\n",
       ":param providers: Optional sequence of providers in order of decreasing\n",
       "    precedence. Values can either be provider names or tuples of\n",
       "    (provider name, options dict). If not provided, then all available\n",
       "    providers are used with the default precedence.\n",
       ":param provider_options: Optional sequence of options dicts corresponding\n",
       "    to the providers listed in 'providers'.\n",
       "\n",
       "The model type will be inferred unless explicitly set in the SessionOptions.\n",
       "To explicitly set:\n",
       "\n",
       "::\n",
       "\n",
       "    so = onnxruntime.SessionOptions()\n",
       "    # so.add_session_config_entry('session.load_model_format', 'ONNX') or\n",
       "    so.add_session_config_entry('session.load_model_format', 'ORT')\n",
       "\n",
       "A file extension of '.ort' will be inferred as an ORT format model.\n",
       "All other filenames are assumed to be ONNX format models.\n",
       "\n",
       "'providers' can contain either names or names and options. When any options\n",
       "are given in 'providers', 'provider_options' should not be used.\n",
       "\n",
       "The list of providers is ordered by precedence. For example\n",
       "`['CUDAExecutionProvider', 'CPUExecutionProvider']`\n",
       "means execute a node using `CUDAExecutionProvider`\n",
       "if capable, otherwise execute using `CPUExecutionProvider`.\n",
       "\u001b[0;31mFile:\u001b[0m           ~/opt/miniconda3/envs/genki/lib/python3.9/site-packages/onnxruntime/capi/onnxruntime_inference_collection.py\n",
       "\u001b[0;31mType:\u001b[0m           type\n",
       "\u001b[0;31mSubclasses:\u001b[0m     "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "InferenceSession?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c8ea362-d0ff-484c-af96-6f94c7642be5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
